{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78db4944-81dd-47a2-9ab7-e9b9aa0ae763",
   "metadata": {},
   "source": [
    "# ON VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e5b176ae-ac7b-4fcc-bc16-41ab450814c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import PoseModule as pm\n",
    "\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture('videos/3.mp4')\n",
    "\n",
    "pTime = 0\n",
    "\n",
    "detector = pm.poseDetector( upBody=True, smooth=True, detectionCon=0.9, trackCon=0.9)\n",
    "count = 0\n",
    "dir = 0\n",
    "\n",
    "while True:\n",
    "    \n",
    "    success, img = cap.read()\n",
    "    # Check if the frame was successfully captured\n",
    "    if not success:\n",
    "        print(\"Video playback completed or file not found.\")\n",
    "        break\n",
    "        \n",
    "    # # cv2.resize(img, (1280,720))\n",
    "    # img = cv2.imread('test0.jpg')\n",
    "    \n",
    "    img = detector.findPose(img, False)\n",
    "    lmList = detector.findPosition(img, draw=False)\n",
    "    # print(lmList)\n",
    "    \n",
    "    if len(lmList) != 0:\n",
    "        # Right Arm\n",
    "        angle = detector.findAngle(img, 12,14,16)\n",
    "        # Left Arm\n",
    "        angle = detector.findAngle(img, 11,13,15)\n",
    "        # print(angle)\n",
    "        \n",
    "        per = np.interp(angle, (35,165), (100,0))\n",
    "        # print(per)\n",
    "       \n",
    "        bar = np.interp(angle, (35,165), (100,650))\n",
    "        \n",
    "        # check for the weight curls\n",
    "        color = (255,0,255)\n",
    "\n",
    "        if per == 100:\n",
    "            # color = (0,255,0)\n",
    "            if dir == 0:\n",
    "                count += 0.5\n",
    "                dir = 1\n",
    "        if per == 0:\n",
    "            # color = (0,255,0)\n",
    "            if dir == 1:\n",
    "                count += 0.5\n",
    "                dir = 0\n",
    "                \n",
    "        # print(count)\n",
    "        gradient_color = (int((1 - (per / 100)) * 255), int((per / 100) * 255), 0)\n",
    "        \n",
    "        # Draw bar\n",
    "        cv2.rectangle(img,(1100,100),(1175,650),  (255,255,255) , 2)\n",
    "        cv2.rectangle(img,(1100, int(bar)),(1175,650),  gradient_color , cv2.FILLED)\n",
    "        cv2.putText(img, f'{int(per)}%', (1100,75), cv2.FONT_HERSHEY_PLAIN, 5, (255,255,255), 5)\n",
    "        \n",
    "        # Show Curl Count\n",
    "        cv2.rectangle(img,(0,300),(250,500),  (0,0,255) , cv2.FILLED)\n",
    "        cv2.putText(img, str(count), (50,425), cv2.FONT_HERSHEY_PLAIN, 5, (255,255,255), 5)\n",
    "        \n",
    "    # Resize the frame FOR VIDEOS\n",
    "    scale_percentage = 50\n",
    "    width = int(img.shape[1] * scale_percentage / 200)\n",
    "    height = int(img.shape[0] * scale_percentage / 200)\n",
    "    img = cv2.resize(img, (width, height))\n",
    "    \n",
    "    cTime = time.time()\n",
    "    fps = 1/(cTime-pTime)\n",
    "    pTime = cTime\n",
    "    # cv2.putText(img, str(int(fps)), (30,50), cv2.FONT_HERSHEY_PLAIN, 2, (255,0,0), 2)\n",
    "\n",
    "    \n",
    "    cv2.imshow(\"Image\", img)\n",
    "\n",
    "    # Close the window and exit loop when 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc8d598-48b4-4f4e-ab8a-ceb327148158",
   "metadata": {},
   "source": [
    "# LIVE *WEBCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e44965e-975f-4de3-b658-53606af5cef3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import PoseModule as pm\n",
    "\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "pTime = 0\n",
    "\n",
    "detector = pm.poseDetector( upBody=True, smooth=True, detectionCon=0.9, trackCon=0.9)\n",
    "count = 0\n",
    "dir = 0\n",
    "\n",
    "while True:\n",
    "    \n",
    "    success, img = cap.read()\n",
    "    # Check if the frame was successfully captured\n",
    "    if not success:\n",
    "        print(\"Video playback completed or file not found.\")\n",
    "        break\n",
    "        \n",
    "    # # cv2.resize(img, (1280,720))\n",
    "    # img = cv2.imread('test0.jpg')\n",
    "    \n",
    "    img = detector.findPose(img, False)\n",
    "    lmList = detector.findPosition(img, draw=False)\n",
    "    # print(lmList)\n",
    "    \n",
    "    if len(lmList) != 0:\n",
    "        # Right Arm\n",
    "        angle = detector.findAngle(img, 12,14,16)\n",
    "        # Left Arm\n",
    "        angle = detector.findAngle(img, 11,13,15)\n",
    "        # print(angle)\n",
    "        \n",
    "        per = np.interp(angle, (35,165), (100,0))\n",
    "        # print(per)\n",
    "       \n",
    "        bar = np.interp(angle, (35,165), (90,430))\n",
    "        \n",
    "        # check for the weight curls\n",
    "        color = (255,0,255)\n",
    "\n",
    "        if per == 100:\n",
    "            # color = (0,255,0)\n",
    "            if dir == 0:\n",
    "                count += 0.5\n",
    "                dir = 1\n",
    "        if per == 0:\n",
    "            # color = (0,255,0)\n",
    "            if dir == 1:\n",
    "                count += 0.5\n",
    "                dir = 0\n",
    "        # print(count)\n",
    "\n",
    "        # gradient color for the bar \n",
    "        start_color = np.array([150, 150, 150])  # Gray\n",
    "        end_color = np.array([0, 200, 0])  # Green\n",
    "\n",
    "        gradient_color = tuple((start_color + (per / 100) * (end_color - start_color)).astype(np.int32).tolist())\n",
    "\n",
    "        # Draw bar\n",
    "        cv2.rectangle(img, (570, 90), (600, 430), (255, 255, 255), 2)\n",
    "        cv2.rectangle(img, (570, int(bar)), (600, 430), gradient_color, cv2.FILLED)\n",
    "        cv2.putText(img, f'{int(per)}%', (570, 75), cv2.FONT_HERSHEY_PLAIN, 1.4, (255, 255, 255), 2)\n",
    "\n",
    "        # Show Curl Count\n",
    "        cv2.rectangle(img,(0,50),(50,100),  (0,0,255) , cv2.FILLED)\n",
    "        cv2.putText(img, str(count), (5,80), cv2.FONT_HERSHEY_PLAIN, 1.3, (255,255,255), 2)\n",
    "        \n",
    "    # Resize the frame FOR VIDEOS\n",
    "    # scale_percentage = 50\n",
    "    # width = int(img.shape[1] * scale_percentage / 200)\n",
    "    # height = int(img.shape[0] * scale_percentage / 200)\n",
    "    # img = cv2.resize(img, (width, height))\n",
    "    \n",
    "    cTime = time.time()\n",
    "    fps = 1/(cTime-pTime)\n",
    "    pTime = cTime\n",
    "    # cv2.putText(img, str(int(fps)), (30,50), cv2.FONT_HERSHEY_PLAIN, 2, (255,0,0), 2)\n",
    "\n",
    "    \n",
    "    cv2.imshow(\"Image\", img)\n",
    "\n",
    "    # Close the window and exit loop when 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc91e45-95e9-46b0-8b31-8d4bd1372d03",
   "metadata": {},
   "source": [
    "# Improver Version BOTH ARMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a3e3126-dd73-4045-abe5-0af0b8b9ad3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import PoseModule as pm\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "pTime = 0\n",
    "\n",
    "detector = pm.poseDetector(upBody=True, smooth=True, detectionCon=0.9, trackCon=0.9)\n",
    "count_right = 0\n",
    "count_left = 0\n",
    "dir_right = 0\n",
    "dir_left = 0\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        print(\"Video playback completed or file not found.\")\n",
    "        break\n",
    "\n",
    "    img = detector.findPose(img, False)\n",
    "    lmList = detector.findPosition(img, draw=False)\n",
    "\n",
    "    if len(lmList) != 0:\n",
    "        # Right Arm\n",
    "        angle_right = detector.findAngle(img, 12, 14, 16)\n",
    "        per_right = np.interp(angle_right, (35, 165), (100, 0))\n",
    "        bar_right = np.interp(angle_right, (35, 165), (90, 430))\n",
    "        if per_right == 100:\n",
    "            if dir_right == 0:\n",
    "                count_right += 0.5\n",
    "                dir_right = 1\n",
    "        if per_right == 0:\n",
    "            if dir_right == 1:\n",
    "                count_right += 0.5\n",
    "                dir_right = 0\n",
    "\n",
    "        # Left Arm\n",
    "        angle_left = detector.findAngle(img, 11, 13, 15)\n",
    "        per_left = np.interp(angle_left, (35, 165), (100, 0))\n",
    "        bar_left = np.interp(angle_left, (35, 165), (90, 430))\n",
    "        if per_left == 100:\n",
    "            if dir_left == 0:\n",
    "                count_left += 0.5\n",
    "                dir_left = 1\n",
    "        if per_left == 0:\n",
    "            if dir_left == 1:\n",
    "                count_left += 0.5\n",
    "                dir_left = 0\n",
    "\n",
    "        # Gradient color for the bars\n",
    "        start_color = np.array([150, 150, 150])  # Gray\n",
    "        end_color = np.array([0, 200, 0])  # Green\n",
    "        gradient_color_right = tuple((start_color + (per_right / 100) * (end_color - start_color)).astype(np.int32).tolist())\n",
    "        gradient_color_left = tuple((start_color + (per_left / 100) * (end_color - start_color)).astype(np.int32).tolist())\n",
    "\n",
    "        # Draw bars with rounded corners\n",
    "        # Left Arm (displayed on the right side due to webcam mirroring)\n",
    "        cv2.rectangle(img, (570, 90), (600, 430), (200, 200, 200), -1)\n",
    "        cv2.rectangle(img, (570, int(bar_left)), (600, 430), gradient_color_left, -1)\n",
    "        cv2.putText(img, f'{int(per_left)}%', (540, 75), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (50, 50, 50), 2)\n",
    "        # Right Arm (displayed on the left side due to webcam mirroring)\n",
    "        cv2.rectangle(img, (50, 90), (80, 430), (200, 200, 200), -1)\n",
    "        cv2.rectangle(img, (50, int(bar_right)), (80, 430), gradient_color_right, -1)\n",
    "        cv2.putText(img, f'{int(per_right)}%', (20, 75), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (50, 50, 50), 2)\n",
    "\n",
    "        # Show Curl Count with rounded rectangle\n",
    "        # Left Arm (displayed on the right side due to webcam mirroring)\n",
    "        cv2.rectangle(img, (520, 40), (610, 110), (50, 50, 50), -1, cv2.LINE_AA)\n",
    "        cv2.putText(img, str(count_left), (530, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (220, 220, 220), 2)\n",
    "        # Right Arm (displayed on the left side due to webcam mirroring)\n",
    "        cv2.rectangle(img, (10, 40), (100, 110), (50, 50, 50), -1, cv2.LINE_AA)\n",
    "        cv2.putText(img, str(count_right), (20, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (220, 220, 220), 2)\n",
    "\n",
    "    cTime = time.time()\n",
    "    fps = 1 / (cTime - pTime)\n",
    "    pTime = cTime\n",
    "\n",
    "    # Display FPS\n",
    "    cv2.putText(img, f'FPS: {int(fps)}', (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (50, 50, 50), 1)\n",
    "\n",
    "    cv2.imshow(\"Image\", img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b5ad51-024b-4192-a99c-e13554b67103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc67c11e-616a-49ed-b6fb-c33c5a17f96d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Version 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cde3c1ca-cf1c-4d99-860d-62cb0ab33fb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AdvancedComputerVision\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import PoseModule as pm\n",
    "from PyQt5.QtWidgets import QApplication, QMainWindow, QLabel, QVBoxLayout, QPushButton, QWidget, QProgressBar\n",
    "from PyQt5.QtGui import QImage, QPixmap\n",
    "from PyQt5.QtCore import QTimer\n",
    "from PyQt5.QtGui import QPalette, QColor\n",
    "\n",
    "class App(QMainWindow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize detector and other variables\n",
    "        self.detector = pm.poseDetector(upBody=True, smooth=True, detectionCon=0.9, trackCon=0.9)\n",
    "        self.count_right = 0\n",
    "        self.count_left = 0\n",
    "        self.dir_right = 0\n",
    "        self.dir_left = 0\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "\n",
    "        # UI Elements\n",
    "        self.initUI()\n",
    "        self.applyStyles()\n",
    "\n",
    "    def initUI(self):\n",
    "        self.setWindowTitle('Pose Detection App')\n",
    "\n",
    "        # Main layout\n",
    "        layout = QVBoxLayout()\n",
    "\n",
    "        # Video display\n",
    "        self.label_video = QLabel(self)\n",
    "        layout.addWidget(self.label_video)\n",
    "\n",
    "        # Progress bars and labels\n",
    "        self.right_progress = QProgressBar(self)\n",
    "        self.left_progress = QProgressBar(self)\n",
    "        self.right_label = QLabel('Right Arm:', self)\n",
    "        self.left_label = QLabel('Left Arm:', self)\n",
    "        layout.addWidget(self.right_label)\n",
    "        layout.addWidget(self.right_progress)\n",
    "        layout.addWidget(self.left_label)\n",
    "        layout.addWidget(self.left_progress)\n",
    "\n",
    "        # Control buttons\n",
    "        self.start_button = QPushButton('Start', self)\n",
    "        self.start_button.clicked.connect(self.start)\n",
    "        layout.addWidget(self.start_button)\n",
    "        \n",
    "        self.stop_button = QPushButton('Stop', self)\n",
    "        self.stop_button.clicked.connect(self.stop)\n",
    "        layout.addWidget(self.stop_button)\n",
    "        \n",
    "        self.exit_button = QPushButton('Exit', self)\n",
    "        self.exit_button.clicked.connect(self.close)\n",
    "        layout.addWidget(self.exit_button)\n",
    "\n",
    "        container = QWidget()\n",
    "        container.setLayout(layout)\n",
    "        self.setCentralWidget(container)\n",
    "\n",
    "        # Timer for video capture\n",
    "        self.timer = QTimer(self)\n",
    "        self.timer.timeout.connect(self.update_frame)\n",
    "        self.timer.start(20)\n",
    "\n",
    "        \n",
    "    def applyStyles(self):\n",
    "        # Set the main window's style\n",
    "        self.setStyleSheet(\"\"\"\n",
    "            QMainWindow {\n",
    "                background-color: #333;\n",
    "            }\n",
    "            QLabel {\n",
    "                color: #FFF;\n",
    "                font-size: 16px;\n",
    "            }\n",
    "            QPushButton {\n",
    "                background-color: #555;\n",
    "                color: #FFF;\n",
    "                padding: 10px;\n",
    "                border: none;\n",
    "                border-radius: 5px;\n",
    "            }\n",
    "            QPushButton:hover {\n",
    "                background-color: #777;\n",
    "            }\n",
    "            QProgressBar {\n",
    "                border: 2px solid #FFF;\n",
    "                border-radius: 5px;\n",
    "                text-align: center;\n",
    "                color: #FFF;\n",
    "            }\n",
    "            QProgressBar::chunk {\n",
    "                background-color: #555;\n",
    "                border-radius: 3px;\n",
    "            }\n",
    "        \"\"\")\n",
    "        \n",
    "    def start(self):\n",
    "        self.timer.start(20)\n",
    "\n",
    "    def stop(self):\n",
    "        self.timer.stop()\n",
    "\n",
    "    def setGradientColor(self, progressBar, percentage):\n",
    "        # Define the colors for the gradient\n",
    "        cold_color = QColor(255, 0, 0)  # Blue for cold\n",
    "        hot_color = QColor(0, 255, 0)   # Red for hot\n",
    "\n",
    "        # Calculate the gradient color based on percentage\n",
    "        gradient_color = QColor(\n",
    "            int(cold_color.red() + percentage * (hot_color.red() - cold_color.red()) / 100),\n",
    "            int(cold_color.green() + percentage * (hot_color.green() - cold_color.green()) / 100),\n",
    "            int(cold_color.blue() + percentage * (hot_color.blue() - cold_color.blue()) / 100)\n",
    "        )\n",
    "\n",
    "        # Apply the gradient color to the progress bar\n",
    "        progressBar.setStyleSheet(\n",
    "            f\"QProgressBar::chunk {{ background-color: {gradient_color.name()}; }}\"\n",
    "        )\n",
    "\n",
    "    def update_frame(self):\n",
    "        ret, img = self.cap.read()\n",
    "\n",
    "        # Initialize per_right and per_left\n",
    "        per_right = 0\n",
    "        per_left = 0\n",
    "\n",
    "        if ret:\n",
    "            img = self.detector.findPose(img, False)\n",
    "            lmList = self.detector.findPosition(img, draw=False)\n",
    "\n",
    "            if len(lmList) != 0:\n",
    "                # Right Arm\n",
    "                angle_right = self.detector.findAngle(img, 12, 14, 16)\n",
    "                per_right = np.interp(angle_right, (35, 165), (100, 0))\n",
    "\n",
    "                # Check for rep completion for right arm\n",
    "                if per_right >= 99:  # Close to 100\n",
    "                    if self.dir_right == 0:\n",
    "                        self.count_right += 0.5\n",
    "                        self.dir_right = 1\n",
    "                elif per_right <= 1:  # Close to 0\n",
    "                    if self.dir_right == 1:\n",
    "                        self.count_right += 0.5\n",
    "                        self.dir_right = 0\n",
    "\n",
    "                # Left Arm\n",
    "                angle_left = self.detector.findAngle(img, 11, 13, 15)\n",
    "                per_left = np.interp(angle_left, (35, 165), (100, 0))\n",
    "\n",
    "                # Check for rep completion for left arm\n",
    "                if per_left >= 99:  # Close to 100\n",
    "                    if self.dir_left == 0:\n",
    "                        self.count_left += 0.5\n",
    "                        self.dir_left = 1\n",
    "                elif per_left <= 1:  # Close to 0\n",
    "                    if self.dir_left == 1:\n",
    "                        self.count_left += 0.5\n",
    "                        self.dir_left = 0\n",
    "\n",
    "            # Convert the frame to QPixmap and display it on QLabel\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            height, width, channel = img.shape\n",
    "            bytes_per_line = 3 * width\n",
    "            q_img = QImage(img.data, width, height, bytes_per_line, QImage.Format_RGB888)\n",
    "            pixmap = QPixmap.fromImage(q_img)\n",
    "            self.label_video.setPixmap(pixmap)\n",
    "\n",
    "            # Update progress bars\n",
    "            self.right_progress.setValue(int(per_right))\n",
    "            self.left_progress.setValue(int(per_left))\n",
    "            \n",
    "            # Set gradient colors\n",
    "            self.setGradientColor(self.right_progress, int(per_right))\n",
    "            self.setGradientColor(self.left_progress, int(per_left))\n",
    "\n",
    "            self.right_label.setText(f\"Right Arm: {int(self.count_right)} reps\")\n",
    "            self.left_label.setText(f\"Left Arm: {int(self.count_left)} reps\")\n",
    "\n",
    "    def closeEvent(self, event):\n",
    "        self.cap.release()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = QApplication(sys.argv)\n",
    "    ex = App()\n",
    "    ex.show()\n",
    "    sys.exit(app.exec_())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AdvancedComputerVision",
   "language": "python",
   "name": "advancedcomputervision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
